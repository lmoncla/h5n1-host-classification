{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify avian sequences into domestic and wild\n",
    "\n",
    "Update on June 30, 2022: I am going to make sure I am not missing any wild bird sequences and am also going to update to the newest data. So I re-downloaded all metadata for every sequence that had an HA gene from GISAID. I also updated thte H5N1 nextstrain build with up to date IRD data and will use that input file. \n",
    "\n",
    "August 18, 2020\n",
    "\n",
    "To start on this avian flu project, I would like to use the H5N1 sequences that I have already curated for the avian-flu nextstrain build. While some of the sequences on that site are derived from the Influenza Research Database (which pulls from Genbank), others come from gisaid. Gisaid has an annotation feature where avian sequences can be annotated as domestic or wild, which is really helpful. However, most sequences are not annotated. I figured out when writing the application that sequences can generally be classified by reading the associated abstract or paper. To do that, I need to match gisaid ids with genbank ids, and use those to pull abstracts. In this notebook, I will do the following: \n",
    "\n",
    "1. I downloaded all available H5N1 sequences from gisaid. I did not stipulate whether they required any given segment or any minimum segment length. This downloaded metadata file should provide all the available metadata for all gisaid h5n1 segments. \n",
    "2. Read in this gisaid metadata file to a dictionary containing for each accession number, all of the associated metadata. \n",
    "3. Next, I will read in all of the fasta files for H5N1 that are currently used for the avian-flu repo. These fasta files live in `avian-flu/data/`. I have already done a bit of work to classify hosts for the avian flu build as bird, human, nonhuman mammal, and environment. I feel pretty confident that the majority of sequences that are ambiguous will be goose and duck. So, for any sequence annotated as bird whose host in the strain name is goose or duck, then I will pull out the accession number. If the accession is a gisaid accession, then I will check the metadata dictionary to determine whether a. there is a domestic/wild annotation and b. whether there is an associated genbank id.\n",
    "4. If there is no annotation and no genbank id, then it will be really challenging to classify. If there is an annotation, then we will use that. If there is no annotation, but there is a genbank id, then I will record that genbank id and use it to look up and output an associated abstract for that sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the Entrez feature from bio\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "import re\n",
    "import time, datetime\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in new and old metadata files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_existing_metadata_file(old_metadata_file):\n",
    "    \n",
    "    output_dict = {}\n",
    "    \n",
    "    with open(old_metadata_file, \"r\") as infile: \n",
    "        for line in infile: \n",
    "            if line.startswith(\"strain\") != True:\n",
    "                strain = line.split(\"\\t\")[0]\n",
    "                virus = line.split(\"\\t\")[1]\n",
    "                isolate_id = line.split(\"\\t\")[2]\n",
    "                date = line.split(\"\\t\")[3]\n",
    "                region = line.split(\"\\t\")[4]\n",
    "                country = line.split(\"\\t\")[5]\n",
    "                division = line.split(\"\\t\")[6]\n",
    "                location = line.split(\"\\t\")[7]\n",
    "                host = line.split(\"\\t\")[8]\n",
    "                originating_lab = line.split(\"\\t\")[9]\n",
    "                submitting_lab = line.split(\"\\t\")[10]\n",
    "                host_species = line.split(\"\\t\")[11]\n",
    "                host_species_standardized = line.split(\"\\t\")[12]\n",
    "                domestic_wild = line.split(\"\\t\")[13]\n",
    "                annotation_method = line.split(\"\\t\")[14]\n",
    "                genbank_id = line.split(\"\\t\")[15]\n",
    "                pubmed_id = line.split(\"\\t\")[16].strip()\n",
    "                \n",
    "                output_dict[strain] = {\"virus\":virus, \"isolate_id\":isolate_id, \"date\":date, \"region\":region, \n",
    "                                      \"country\":country, \"division\":division, \"location\":location, \"host\":host, \n",
    "                                      \"originating_lab\":originating_lab, \"submitting_lab\":submitting_lab, \n",
    "                                      \"host_species\":host_species, \"host_species_standardized\":host_species_standardized, \n",
    "                                      \"domestic_wild\":domestic_wild, \"annotation_method\":annotation_method, \n",
    "                                       \"genbank_id\":genbank_id, \"pubmed_id\":pubmed_id}\n",
    "    return(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_new_metadata_file(new_metadata_file, old_metadata_dict, new_strains_file):\n",
    "    \n",
    "    with open(new_strains_file, \"w\") as outfile: \n",
    "        outfile.write(\"\")\n",
    "    \n",
    "    with open(new_metadata_file, \"r\") as infile: \n",
    "        for line in infile: \n",
    "            if line.startswith(\"strain\") == True: \n",
    "                with open(new_strains_file, \"a\") as outfile: \n",
    "                    outfile.write(line)\n",
    "            else: \n",
    "                strain = line.split(\"\\t\")[0]\n",
    "                \n",
    "                if strain not in old_metadata_dict: \n",
    "                    with open(new_strains_file, \"a\") as outfile: \n",
    "                        outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in new gisaid excel file, clean it up, and read in as metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"remove non-ascii characters that end up in these gisaid columns. the \\\\xd{0D} shows up in text wrangler as \n",
    "an upside down question mark\"\"\"\n",
    "\n",
    "def clean(string: str = '') -> str:\n",
    "    if type(string) == str:\n",
    "        \n",
    "        #return(re.sub(r'[^\\x00-\\x7F]+',' ', string)\n",
    "        return string.replace('\\r\\n', '').replace('\\n', '').replace('&quot;', '\"').replace('\\\\x{0D}', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_excel_file(input_excel_metadata):\n",
    "    output_filename = input_excel_metadata.replace(\".xls\",\"-cleaned.tsv\")\n",
    "    \n",
    "    \"\"\"in order to remove stupid non-ascii characters, the only way is to remove them while reading in with the\n",
    "    converters argument. This allows you to specify how to clean certain columns with custom functions. I want to \n",
    "    run clean, which removes non-ascii characters, on all columns. So this first bit is to read in the column \n",
    "    names and generate the converters dictionary\"\"\" \n",
    "    d = pd.read_excel(input_excel_metadata, header=0)\n",
    "    converters = {x: clean for x in d.columns}\n",
    "    \n",
    "    \"\"\"Then, read in again, do 1 more find and replace (this is necessary still somehow) and write to csv\"\"\"\n",
    "    df = pd.read_excel(input_excel_metadata, header=0, converters = converters)\n",
    "    \n",
    "    # replace newlines in columns \n",
    "    df = df.replace('\\n','', regex=True)    \n",
    "    \n",
    "    # write to tsv\n",
    "    df.to_csv(output_filename, sep=\"\\t\", index=False)\n",
    "    return(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_metadata_file(file):\n",
    "    count = 0\n",
    "    metadata_dict = {}\n",
    "    genes = {\"PB2\":{\"gisaid_id\":1,\"genbank_id\":53},\n",
    "            \"PB1\":{\"gisaid_id\":2,\"genbank_id\":54},\n",
    "            \"PA\":{\"gisaid_id\":3,\"genbank_id\":55},\n",
    "            \"HA\":{\"gisaid_id\":4,\"genbank_id\":56},\n",
    "            \"NP\":{\"gisaid_id\":5,\"genbank_id\":57},\n",
    "            \"NA\":{\"gisaid_id\":6,\"genbank_id\":58},\n",
    "            \"MP\":{\"gisaid_id\":7,\"genbank_id\":59},\n",
    "            \"NS\":{\"gisaid_id\":8,\"genbank_id\":60},}\n",
    "    \n",
    "    with open(file, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            count += 1\n",
    "            if len(line.split(\"\\t\")) < 63:\n",
    "                print(count)\n",
    "            strain_name = line.split(\"\\t\")[11].strip()\n",
    "            passage_history = line.split(\"\\t\")[14].strip()\n",
    "            host = line.split(\"\\t\")[16].strip()\n",
    "            vacc_status = line.split(\"\\t\")[47].strip()\n",
    "            domestic_status = line.split(\"\\t\")[51].strip()\n",
    "\n",
    "            for gene in genes: \n",
    "                gisaid_id_column = genes[gene]['gisaid_id']\n",
    "                gisaid_id = line.split(\"\\t\")[gisaid_id_column].split(\"|\")[0]\n",
    "                genbank_id_column = genes[gene]['genbank_id']\n",
    "                genbank_id = line.split(\"\\t\")[genbank_id_column]\n",
    "\n",
    "                # add to dictionary \n",
    "                metadata_dict[gisaid_id] = {\"genbank_id\":genbank_id,\"strain\":strain_name,\"passage\":passage_history,\n",
    "                                           \"vaccination_status\":vacc_status,\"domestic_wild\":domestic_status,\"host\":host}\n",
    "\n",
    "        return(metadata_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in files \n",
    "\n",
    "This includes: \n",
    "1. avian species synonsyms: to standardize host species \n",
    "2. exclude file: to exclude specfic strains \n",
    "3. strain host fixes: this includes strains for which I just manually annotated the host because it was obvious to a human, but would have been not obvious programmatically \n",
    "4. classified abstracts: a text file containing a list of abstracts and their classifications \n",
    "5. individual strains from abstracts: for papers where there was a mix of strains domestic and wild, I sometimes annotated them one by one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"I have an avian species synonyms document which both corrects spelling errors and standardizes avian host\n",
    "annotations so that they all match. This document also contains assignments for these species as to whether they\n",
    "are domestic or wild. Some species like duck and goose are not specific enough, but others like heron are. This\n",
    "function will read in that file and output a dictionary with the original species name, the corrected name, and the \n",
    "domestic/wild classification\"\"\"\n",
    "\n",
    "def read_in_avian_species_synonyms(synonyms_doc):\n",
    "    fixes_dict = {}\n",
    "    with open(synonyms_doc, \"r\") as infile: \n",
    "        for line in infile: \n",
    "            if not line.startswith(\"#\"):\n",
    "                if len(line.split(\"\\t\")) == 3:\n",
    "                    species = line.split(\"\\t\")[0]\n",
    "                    fix = line.split(\"\\t\")[1]\n",
    "                    domestic_wild = line.split(\"\\t\")[2].strip()\n",
    "\n",
    "                    fixes_dict[species] = {\"fix\":fix, \"domestic_wild\":domestic_wild}\n",
    "                else:\n",
    "                    species = line.split(\"\\t\")[0].strip()\n",
    "                    fixes_dict[species] = {\"fix\":\"\", \"domestic_wild\":\"\"}\n",
    "    return(fixes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"some strains have weird passage histories or should otherwise be excluded. This is a list to hold those\"\"\"\n",
    "\n",
    "def read_in_exclude_file(exclude_file):\n",
    "    exclude_dict = {}\n",
    "    \n",
    "    with open(exclude_file, \"r\") as infile: \n",
    "        for line in infile: \n",
    "            if \"#\" not in line and line != \"\\n\":\n",
    "                strain_name = line.split(\"\\t\")[0]\n",
    "                accession = line.split(\"\\t\")[1]\n",
    "                exclude_dict[strain_name] = accession\n",
    "                \n",
    "    return(exclude_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"some strains are improperly formatted and need to have a host annotation added explicitly\"\"\"\n",
    "\n",
    "def read_in_strain_host_fixes(strain_host_fixes_file):\n",
    "    \n",
    "    strain_host_fixes_dict = {}\n",
    "    \n",
    "    with open(strain_host_fixes_file, \"r\") as infile: \n",
    "        for line in infile: \n",
    "            if \"#\" not in line:\n",
    "                strain_name = line.split(\"\\t\")[0]\n",
    "                host_annotation = line.split(\"\\t\")[1]\n",
    "                corrected_strain = line.split(\"\\t\")[2]\n",
    "                strain_host_fixes_dict[strain_name] = {\"host_species\":host_annotation,\"corrected_strain\":corrected_strain}\n",
    "                \n",
    "    return(strain_host_fixes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_classified_abstracts(abstracts_classified_file):\n",
    "    output_dict = {}\n",
    "    \n",
    "    with open(abstracts_classified_file, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            if line != \"\\n\":\n",
    "                PMID = line.split(\"\\t\")[0]\n",
    "                domestic_wild = line.split(\"\\t\")[1]\n",
    "                notes = line.split(\"\\t\")[2]\n",
    "\n",
    "                output_dict[PMID] = domestic_wild\n",
    "    return(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_strain_specific_classifications_file(strain_classification_file):\n",
    "    \n",
    "    output_dict = {}\n",
    "    with open(strain_classification_file, \"r\") as infile: \n",
    "        for line in infile:\n",
    "            if line != \"\\n\":\n",
    "                strain_name = line.split(\"\\t\")[0]                \n",
    "                domestic_wild = line.split(\"\\t\")[1]\n",
    "                PMID = line.split(\"\\t\")[2].strip()\n",
    "                \n",
    "                if PMID not in output_dict: \n",
    "                    output_dict[PMID] = {}\n",
    "                \n",
    "                output_dict[PMID][strain_name] = domestic_wild\n",
    "    return(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize host names and such "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"given the species fixes in the annotations file, standardize the species annotation\"\"\"\n",
    "\n",
    "def standardize_host_species(strain_name, host_group, fixes_dict):\n",
    "    \n",
    "    # standardize host species names using fix file and and categorize domestic/wild by species if possible\n",
    "    if host_group.lower() == \"avian\": \n",
    "        host_species = strain_name.split(\"/\")[1].lower()\n",
    "            \n",
    "        if host_species in fixes_dict:\n",
    "            species_fix = fixes_dict[host_species]['fix']\n",
    "            \n",
    "        else:\n",
    "            print(\"not in dictionary: \",host_species, strain_name)\n",
    "            species_fix = host_species\n",
    "                \n",
    "    else:\n",
    "        host_species = host_group\n",
    "        species_fix = host_group\n",
    "\n",
    "    return(host_species, species_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"given a host species, determine whether that species has a clear domestic/wild classification\"\"\"\n",
    "\n",
    "def check_for_annotation_by_species(host_species,fixes_dict):\n",
    "    \n",
    "    if host_species in fixes_dict:\n",
    "        domestic_wild_status = fixes_dict[host_species]['domestic_wild']\n",
    "    \n",
    "    else:\n",
    "        domestic_wild_status = \"\"\n",
    "    \n",
    "    return(domestic_wild_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"given an accession, check to see whether it is from gisaid and if so, whether it has a domestic wild annotation\"\"\"\n",
    "\n",
    "def check_for_annotation_by_gisaid(accession,metadata_dict):\n",
    "    \n",
    "    if accession.startswith(\"EPI\") and len(accession) == 10 and accession in metadata_dict:\n",
    "        domestic_wild_status = metadata_dict[accession]['domestic_wild'].lower()\n",
    "    else:\n",
    "        domestic_wild_status = \"\"\n",
    "        \n",
    "    return(domestic_wild_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_status_and_annotation_method(domestic_wild_status_by_species,domestic_wild_status_by_gisaid):\n",
    "    \n",
    "    # first check to make sure that the different methods did not return conflicting annotations\n",
    "    if domestic_wild_status_by_species != \"\" and domestic_wild_status_by_gisaid != \"\" and domestic_wild_status_by_species != domestic_wild_status_by_gisaid:\n",
    "        print(\"conflicting annotations \",domestic_wild_status_by_species,domestic_wild_status_by_gisaid)\n",
    "    \n",
    "    # if the species is informative and gisaid had an annotation\n",
    "    elif domestic_wild_status_by_species != \"\" and domestic_wild_status_by_gisaid != \"\" and domestic_wild_status_by_species == domestic_wild_status_by_gisaid:\n",
    "        domestic_wild = domestic_wild_status_by_species\n",
    "        annotation_method = \"species name and gisaid\"\n",
    "    \n",
    "    # if only the species could be used the classify\n",
    "    elif domestic_wild_status_by_species != \"\" and domestic_wild_status_by_gisaid == \"\":\n",
    "        annotation_method = \"species name\"\n",
    "        domestic_wild = domestic_wild_status_by_species\n",
    "    \n",
    "    # if only gisaid could be used to classify\n",
    "    elif domestic_wild_status_by_species == \"\" and domestic_wild_status_by_gisaid != \"\":\n",
    "        annotation_method = \"gisaid annotation\"\n",
    "        domestic_wild = domestic_wild_status_by_gisaid\n",
    "        \n",
    "    # if neither could be used to classify\n",
    "    elif domestic_wild_status_by_species == \"\" and domestic_wild_status_by_gisaid == \"\":\n",
    "        domestic_wild = \"\"\n",
    "        annotation_method = \"\"\n",
    "    \n",
    "    # if there is somehow another option I'm not thinking of\n",
    "    else:\n",
    "        print(\"something weird is happening!\", domestic_wild_status_by_species,domestic_wild_status_by_gisaid)\n",
    "        \n",
    "    return(domestic_wild, annotation_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"given an accession number, determine if it is from gisaid or genbank. If from gisaid, look up the corresponding\n",
    "genbank id for it if available. If not, return a blank string\"\"\"\n",
    "\n",
    "def return_genbank_accession(accession,metadata_dict):\n",
    "    \n",
    "    accession_stripped = accession.replace(\"_\",\"\").replace(\"-\",\"\")\n",
    " \n",
    "    # if the accession is a gisaid accession\n",
    "    if accession_stripped.startswith(\"EPI\"):\n",
    "        if accession_stripped in metadata_dict:\n",
    "            genbank_id = metadata_dict[accession_stripped]['genbank_id']\n",
    "        else: \n",
    "            genbank_id = \"\"\n",
    "            \n",
    "    elif len(accession_stripped) == 8: \n",
    "        genbank_id = accession   #for a genbank lookup, we need to retain the _ and -, but for gisaid, we do not\n",
    "    \n",
    "    else:\n",
    "        print(\"this does not follow the rules \", accession)\n",
    "        \n",
    "    return(genbank_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"given an accession number, pull the genbank entry that it corresponds to\"\"\"\n",
    "\n",
    "def fetch_genbank_entry(accession_number):\n",
    "    \n",
    "    if accession_number != \"\" and accession_number != \", \":\n",
    "        Entrez.email = \"lhmoncla@gmail.com\"      # need to enter an email\n",
    "\n",
    "        # fetch from the nucleotide database, return a genbank object in text format, with id = genbank accession\n",
    "        handle = Entrez.efetch(db=\"nucleotide\", rettype=\"gb\", retmode=\"text\", id=accession_number)\n",
    "        genbank_result = handle.read()\n",
    "        \n",
    "    else: \n",
    "        genbank_result = \"\"\n",
    "        \n",
    "    return(genbank_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"given a genbank result, pull the pubmed id from it\"\"\"\n",
    "\n",
    "def return_PMID(genbank_result):\n",
    "    if genbank_result != \"\":\n",
    "        SearchStr = 'PUBMED\\\\ \\\\ \\\\ [0-9]{8}'\n",
    "        result = re.search(SearchStr,genbank_result)\n",
    "\n",
    "        if result:\n",
    "            PMID = result.group(0).split(\"   \")[1]\n",
    "        else:\n",
    "            PMID = \"\"\n",
    "            \n",
    "    else:\n",
    "        PMID = \"\"\n",
    "    \n",
    "    return(PMID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_genbank(genbank_id):\n",
    "    from urllib.error import HTTPError\n",
    "\n",
    "    flag = True\n",
    "    \n",
    "    while flag:\n",
    "        try:\n",
    "            time.sleep(0.35) # Sleep; genbank will throw an error if you are hitting it with more than 3 hits per second\n",
    "            genbank_entry = fetch_genbank_entry(genbank_id)\n",
    "            pubmed_id = return_PMID(genbank_entry)\n",
    "            flag = False\n",
    "        except HTTPError as e:\n",
    "            time.sleep(1)\n",
    "            print(e)\n",
    "    \n",
    "    return(pubmed_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_host_species_and_classify(metadata_file, metadata_dict,fixes_dict,exclude_dict,strain_host_fixes_dict,output_file,master_dict):\n",
    "    \n",
    "    with open(output_file, \"w\") as outfile:\n",
    "        line_to_write = \"\\t\".join([\"strain\",\"virus\",\"isolate_id\",\"date\",\"region\",\"country\",\"division\",\"location\",\"host\",\"subtype\",\"originating_lab\",\"submitting_lab\",\"h5_clade\",\"h5_label_clade\",\"host_species\",\"host_species_standardized\",\"domestic_wild\",\"annotation_method\",\"genbank_id\",\"pubmed_id\"])\n",
    "        outfile.write(line_to_write + \"\\n\")\n",
    "    output_dict = {}\n",
    "    \n",
    "    with open(metadata_file, \"r\") as infile: \n",
    "        for line in infile:\n",
    "            if \"originating_lab\" not in line:\n",
    "                strain_name = line.split(\"\\t\")[0]\n",
    "                host_group =  line.split(\"\\t\")[8].lower()\n",
    "                accession = line.split(\"\\t\")[2]\n",
    "\n",
    "                \"\"\"filter out strains that should be excluded\"\"\"\n",
    "                if strain_name not in exclude_dict:\n",
    "                    \n",
    "                    \"\"\"first, see if we have already classified this strain\"\"\"\n",
    "                    if strain_name in master_dict: \n",
    "                        host_species = master_dict[strain_name]['host_species']\n",
    "                        host_species_standardized = master_dict[strain_name]['standardized_host_species']\n",
    "                        domestic_wild = master_dict[strain_name]['domestic_wild']\n",
    "                        annotation_method = master_dict[strain_name]['annotation_method']\n",
    "                        host_group = master_dict[strain_name]['host_group']\n",
    "                        pubmed_id = master_dict[strain_name]['pubmed_id']\n",
    "                        \n",
    "                        # for these, we still need to look up a new genbank id\n",
    "                        genbank_id = return_genbank_accession(accession,metadata_dict)\n",
    "                        \n",
    "                    else:                 \n",
    "                        \"\"\"if the strain is in the strain host fixes doc, add in the host species here; \n",
    "                        else, standardize the host species name with the species synonyms\"\"\"\n",
    "                        if strain_name in strain_host_fixes_dict:\n",
    "                            host_species = strain_host_fixes_dict[strain_name]['host_species']\n",
    "                            host_species_standardized = strain_host_fixes_dict[strain_name]['host_species']\n",
    "\n",
    "                        else:\n",
    "                            host_species,host_species_standardized = standardize_host_species(strain_name, host_group, fixes_dict)\n",
    "\n",
    "\n",
    "                        \"\"\"now, if the host group is avian, check for domestic wild status by its species name and by gisaid\n",
    "                        annotation\"\"\"\n",
    "                        if host_group == \"avian\":\n",
    "                            domestic_wild_status_by_species = check_for_annotation_by_species(host_species,fixes_dict)\n",
    "                            domestic_wild_status_by_gisaid = check_for_annotation_by_gisaid(accession,metadata_dict)\n",
    "                            domestic_wild,annotation_method = return_status_and_annotation_method(domestic_wild_status_by_species,domestic_wild_status_by_gisaid)                \n",
    "\n",
    "                        else:\n",
    "                            domestic_wild = host_group\n",
    "                            annotation_method = \"\"\n",
    "\n",
    "                        \"\"\"now, return the genbank ids\"\"\"\n",
    "                        genbank_id = return_genbank_accession(accession,metadata_dict)\n",
    "\n",
    "\n",
    "                        \"\"\"pull the genbank entry and pubmed id for the associated paper\"\"\"\n",
    "                        pubmed_id = query_genbank(genbank_id)\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \"\"\"now write out a dictionary\"\"\"\n",
    "                    output_dict[strain_name] = {\"host_species\":host_species,\"standardized_host_species\":host_species_standardized,\n",
    "                                               \"domestic_wild\":domestic_wild,\"annotation_method\":annotation_method,\n",
    "                                                \"genbank_id\":genbank_id, \"host_group\":host_group,\"pubmed_id\":pubmed_id}\n",
    "\n",
    "                    line_to_write = \"\\t\".join([host_species,host_species_standardized,domestic_wild,annotation_method,genbank_id,pubmed_id])\n",
    "                    with open(output_file, \"a\") as outfile: \n",
    "                        outfile.write(line.strip() + \"\\t\" + line_to_write + \"\\n\")\n",
    "            \n",
    "    return(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "avian_synonyms_file = \"/Users/lmoncla/src/h5n1-host-classification/all-avian-species.txt\"\n",
    "strain_host_fixes = \"/Users/lmoncla/src/h5n1-host-classification/strain-host-fixes.tsv\"\n",
    "exclude_file = \"/Users/lmoncla/src/h5n1-host-classification/exclude.txt\"\n",
    "\n",
    "todays_date = (datetime.datetime.now()).strftime('%Y-%m-%d')\n",
    "output_file_directory = \"/Users/lmoncla/src/h5n1-host-classification/metadata-with-annotations/\"\n",
    "\n",
    "avian_fixes_dict = read_in_avian_species_synonyms(avian_synonyms_file)\n",
    "to_exclude_dict = read_in_exclude_file(exclude_file)\n",
    "strain_host_fixes_dict = read_in_strain_host_fixes(strain_host_fixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull in abstracts and strains classified by abstracts \n",
    "abstracts_classified_file = \"/Users/lmoncla/src/h5n1-host-classification/abstracts/abstracts-classified-2020-09-28.txt\"\n",
    "strain_classification_file = \"/Users/lmoncla/src/h5n1-host-classification/abstracts/strain_specific_annotations.txt\"\n",
    "\n",
    "classified_by_abstract_dict = read_in_classified_abstracts(abstracts_classified_file)\n",
    "strains_abstract_dict = read_in_strain_specific_classifications_file(strain_classification_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in old metadata and make a new folder with a new file containing only the new strains "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_metadata_file = \"../metadata-with-annotations/metadata_h5n1_ha_final_2020-10-02.txt\"\n",
    "old_metadata_dict = read_existing_metadata_file(old_metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new directory for new strains being updated today \n",
    "todays_date = (datetime.datetime.now()).strftime('%Y-%m-%d')\n",
    "os.mkdir(\"../metadata-with-annotations/\"+str(todays_date)+\"-update\")\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in new metadata file and output new strains \n",
    "new_metadata_file = \"/Users/lmoncla/src/avian-flu/results/metadata-with-clade_h5n1_ha.tsv\"\n",
    "new_strains_file = \"../metadata-with-annotations/\"+str(todays_date)+\"-update/new-strains-\"+str(todays_date)+\".tsv\"\n",
    "read_new_metadata_file(new_metadata_file, old_metadata_dict, new_strains_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in new gisaid data so that we have all the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in new gisaid data into a metadata dictionary \n",
    "#metadata_file = \"/Users/lmoncla/src/h5n1-host-classification/gisaid-data/gisaid-all-h5n1-2020-08-18.txt\"\n",
    "metadata_file = \"/Users/lmoncla/src/h5n1-host-classification/gisaid-data/gisaid-all-h5n1-2022-06-30.xls\"\n",
    "\n",
    "cleaned_metadata_tsv = clean_excel_file(metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dict = read_in_metadata_file(cleaned_metadata_tsv)\n",
    "#metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify the new sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 500: Internal Server Error\n"
     ]
    }
   ],
   "source": [
    "# run for all genes to make sure I have all the hosts I need\n",
    "all_genes_dict = {}\n",
    "\n",
    "output_file = new_strains_file.replace(\".tsv\",\"-with-annotations.tsv\")\n",
    "gene_dict = fix_host_species_and_classify(new_strains_file, metadata_dict,avian_fixes_dict,to_exclude_dict,strain_host_fixes_dict,output_file,all_genes_dict)\n",
    "    \n",
    "# update the dictionary with new entries. This will retain the old keys and values, but add in new ones\n",
    "all_genes_dict.update(gene_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1253"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique, new strains\n",
    "len(all_genes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull abstracts to read\n",
    "\n",
    "Given this new metadata file, for all bird sequences that don't have an annotation yet and do have a pubmed id, pull the abstract so that I can read it to classify. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_unique_PMIDs(metadata_file, PMIDs, cannot_classify, classify_by_abstract):\n",
    "    \n",
    "    with open(metadata_file, \"r\") as infile: \n",
    "        for line in infile: \n",
    "            if \"originating_lab\" not in line:\n",
    "                strain = line.split(\"\\t\")[0]\n",
    "                host_group = line.split(\"\\t\")[8].lower()\n",
    "                domestic_wild = line.split(\"\\t\")[16]\n",
    "                PMID = line.split(\"\\t\")[19].strip()\n",
    "                \n",
    "                if host_group == \"avian\" and domestic_wild == \"\" and PMID != \"\":\n",
    "                    PMIDs.append(PMID)\n",
    "                    classify_by_abstract.append(strain)\n",
    "                elif host_group == \"avian\" and domestic_wild == \"\" and PMID == \"\":\n",
    "                    cannot_classify.append(strain)\n",
    "    \n",
    "    PMIDs = list(set(PMIDs))\n",
    "    cannot_classify = list(set(cannot_classify))\n",
    "    classify_by_abstract = list(set(classify_by_abstract))\n",
    "    return(PMIDs, cannot_classify, classify_by_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_abstract(PMID):\n",
    "    \n",
    "    pmid_handle = Entrez.efetch(db='pubmed', id=PMID, retmode='text', rettype='abstract')\n",
    "    abstract = pmid_handle.read()\n",
    "    \n",
    "    return(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_necessary_abstracts(PMIDs, abstracts_output_filename):\n",
    "    \n",
    "    with open(abstracts_output_filename, \"w\") as outfile: \n",
    "        outfile.write(\"\")\n",
    "    \n",
    "    for p in PMIDs: \n",
    "        abstract = pull_abstract(p)\n",
    "                    \n",
    "        with open(abstracts_output_filename, \"a\") as outfile: \n",
    "            outfile.write(p + \"\\n\")\n",
    "            outfile.write(abstract + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 427 1\n"
     ]
    }
   ],
   "source": [
    "metadata_directory = \"/Users/lmoncla/src/h5n1-host-classification/metadata-with-annotations/2022-07-12-update/\"\n",
    "abstracts_output_filename = \"/Users/lmoncla/src/h5n1-host-classification/metadata-with-annotations/2022-07-12-update/abstracts-\"+todays_date+\".txt\"\n",
    "\n",
    "unique_PMIDs = []\n",
    "cannot_classify = []\n",
    "classify_by_abstract = []\n",
    "\n",
    "metadata_input_file = \"/Users/lmoncla/src/h5n1-host-classification/metadata-with-annotations/2022-07-12-update/new-strains-2022-07-12-with-annotations.tsv\"\n",
    "unique_PMIDs,cannot_classify,classify_by_abstract = collate_unique_PMIDs(metadata_input_file, unique_PMIDs, cannot_classify, classify_by_abstract)\n",
    "\n",
    "# print the number of abstracts I need to read, and the number of strains that can't be classified at all, and the \n",
    "# number of strains that will be captured by abstract classification\n",
    "print(len(unique_PMIDs), len(cannot_classify), len(classify_by_abstract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_necessary_abstracts(unique_PMIDs, abstracts_output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in annotations from abstract reading and make the final cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_classified_abstracts(abstracts_classified_file):\n",
    "    output_dict = {}\n",
    "    \n",
    "    with open(abstracts_classified_file, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            if line != \"\\n\":\n",
    "                PMID = line.split(\"\\t\")[0]\n",
    "                domestic_wild = line.split(\"\\t\")[1]\n",
    "                notes = line.split(\"\\t\")[2]\n",
    "\n",
    "                output_dict[PMID] = domestic_wild\n",
    "    return(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_strain_specific_classifications_file(strain_classification_file):\n",
    "    \n",
    "    output_dict = {}\n",
    "    with open(strain_classification_file, \"r\") as infile: \n",
    "        for line in infile:\n",
    "            if line != \"\\n\":\n",
    "                strain_name = line.split(\"\\t\")[0]                \n",
    "                domestic_wild = line.split(\"\\t\")[1]\n",
    "                PMID = line.split(\"\\t\")[2].strip()\n",
    "                \n",
    "                if PMID not in output_dict: \n",
    "                    output_dict[PMID] = {}\n",
    "                \n",
    "                output_dict[PMID][strain_name] = domestic_wild\n",
    "    return(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_manual_annotations(metadata_file, abstracts_dict, strain_abstract_dict, output_filename):\n",
    "    \n",
    "    with open(output_filename, \"w\") as outfile: \n",
    "        outfile.write(\"\")\n",
    "    \n",
    "    with open(metadata_file, \"r\") as infile: \n",
    "        for line in infile: \n",
    "            if \"originating_lab\" not in line:\n",
    "                strain = line.split(\"\\t\")[0]\n",
    "                host_group = line.split(\"\\t\")[8].lower()\n",
    "                current_domestic_wild = line.split(\"\\t\")[16]\n",
    "                current_annotation_method = line.split(\"\\t\")[17]\n",
    "                PMID = line.split(\"\\t\")[19].strip()\n",
    "                \n",
    "                \"\"\"add in annotations that I manually curated\"\"\"\n",
    "                if host_group == \"avian\" and current_domestic_wild == \"\" and PMID != \"\":\n",
    "                    if PMID in abstracts_dict and abstracts_dict[PMID] != \"\":\n",
    "                        domestic_wild = abstracts_dict[PMID]\n",
    "                        annotation_method = \"manual curation\"\n",
    "                        \n",
    "                        \n",
    "                        \"\"\"if I needed to annotate each strain separately, look that up in the strains file\"\"\"\n",
    "                        if domestic_wild == \"see strain list\":\n",
    "                            if PMID in strain_abstract_dict and strain in strain_abstract_dict[PMID]:\n",
    "                                domestic_wild = strain_abstract_dict[PMID][strain]\n",
    "                                annotation_method = \"manual curation\"\n",
    "                            else:\n",
    "                                domestic_wild = \"\"\n",
    "                    \n",
    "                    else:\n",
    "                        domestic_wild = \"\"\n",
    "                        annotation_method = \"\"\n",
    "                    \n",
    "                    first_part = \"\\t\".join(line.split(\"\\t\")[0:16])\n",
    "                    last_part = \"\\t\".join(line.split(\"\\t\")[18:])\n",
    "                    line_to_write = \"\\t\".join([first_part,domestic_wild, annotation_method,last_part])\n",
    "                \n",
    "                \n",
    "                # if it already has an annotation, or if it doesn't but there isn't an abstract, move on\n",
    "                else:\n",
    "                    line_to_write = line\n",
    "                \n",
    "            else:\n",
    "                line_to_write = line\n",
    "            \n",
    "            \"\"\"write it out\"\"\"\n",
    "            with open(output_filename, \"a\") as outfile: \n",
    "                outfile.write(line_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts_classified_file = \"/Users/lmoncla/src/h5n1-host-classification/abstracts/abstracts-classified-2020-09-28.txt\"\n",
    "strain_classification_file = \"/Users/lmoncla/src/h5n1-host-classification/abstracts/strain_specific_annotations.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_by_abstract_dict = read_in_classified_abstracts(abstracts_classified_file)\n",
    "strains_abstract_dict = read_in_strain_specific_classifications_file(strain_classification_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_directory = \"/Users/lmoncla/src/h5n1-host-classification/metadata-with-annotations/\"\n",
    "todays_date = (datetime.datetime.now()).strftime('%Y-%m-%d')\n",
    "genes_to_run = ['pb2','pb1','pa','ha','np','na','mp','ns']\n",
    "\n",
    "for gene in genes_to_run: \n",
    "    metadata_file = metadata_directory + \"metadata_h5n1_\" + gene + \"_with_accessions_2020-10-02.txt\"\n",
    "    output_filename = metadata_directory + \"metadata_h5n1_\" + gene + \"_final_\"+ todays_date+\".txt\"\n",
    "    add_manual_annotations(metadata_file, classified_by_abstract_dict, strains_abstract_dict, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LHM-basics (python3)",
   "language": "python",
   "name": "lhm-basics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
